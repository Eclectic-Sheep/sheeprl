{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> This notebook was inspired by [https://orobix.github.io/quadra/v1.3.6/tutorials/model_management.html](https://orobix.github.io/quadra/v1.3.6/tutorials/model_management.html)\n",
    "\n",
    "# Model Manager\n",
    "\n",
    "In this notebook, we present the [MlflowModelManager](../sheeprl/utils/model_manager.py) and possible use.\n",
    "It includes methods such as:\n",
    "* Register the model\n",
    "* Retrieve the latest version\n",
    "* Transition the model to a new stage\n",
    "* Delete the model\n",
    "\n",
    "First of all, we need to run the Mlflow server with the artifact store. You can find the instructions for running the Mlflow server [here](https://mlflow.org/docs/latest/tracking.html#tracking-ui). Let's open a new terminal and run the following command:\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> This is one of the possibilities, you could have the server running on another machine, so you just need to set the `tracking_uri` parameter properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Experiment and Registering the Model\n",
    "Second, we launch an experiment, so we need to retrieve the configs and execute the `run_algorithm` function. We train a PPO agent in the CartPole-v1 environment for few steps (we do not want to reach the best performance, but we want to show how SheepRL interprets model management for reinforcement learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from sheeprl.utils.utils import dotdict\n",
    "from sheeprl.cli import check_configs, run_algorithm\n",
    "\n",
    "# To retrieve the configs, we can simulate the cli command\n",
    "# `python sheeprl.py exp=ppo algo.total_steps=1024 model_manager.disabled=False logger@metric.logger=mlflow checkpoint.every=1024 exp_name=mlflow_example metric.logger.tracking_uri=\"http://localhost:5000\"`\n",
    "with hydra.initialize(version_base=\"1.3\", config_path=\"../sheeprl/configs\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"config.yaml\",\n",
    "        overrides=[\n",
    "            \"exp=ppo\",\n",
    "            \"algo.total_steps=1024\",\n",
    "            \"model_manager.disabled=False\",\n",
    "            \"logger@metric.logger=mlflow\",\n",
    "            \"checkpoint.every=1024\",\n",
    "            \"exp_name=mlflow_example\",\n",
    "            \"metric.logger.tracking_uri=http://localhost:5000\",\n",
    "        ],\n",
    "    )\n",
    "    cfg = dotdict(OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True))\n",
    "check_configs(cfg)\n",
    "run_algorithm(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Experiment Info\n",
    "\n",
    "The experiment is logged on MLFlow, and we can retrieve it just  with the following instructions. Moreover, given the experiment, it is possible to retrieve all the runs with the `mlflow.search_runs()` function.\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> You can check this information from a browser, by entering the MLFlow address in a browser, e.g., `http://localhost:5000` if you are running mlflow locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(cfg.metric.logger.tracking_uri)\n",
    "exp = mlflow.get_experiment_by_name(\"mlflow_example\")\n",
    "print(\"Experiment:\", exp)\n",
    "runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n",
    "print(f\"Experiment ({exp.experiment_id}) runs:\")\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Model Info\n",
    "Since we set the `model_manager.disabled` to `False` the PPO Agent is registered in MLFLow, we can get its information with the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sheeprl.utils.mlflow import MlflowModelManager\n",
    "from lightning import Fabric\n",
    "\n",
    "fabric = Fabric(devices=1, accelerator=cfg.fabric.accelerator, precision=cfg.fabric.precision)\n",
    "fabric.launch()\n",
    "model_manager = MlflowModelManager(fabric, cfg.model_manager.tracking_uri)\n",
    "\n",
    "model_info = mlflow.search_registered_models(filter_string=\"name='mlflow_example_agent'\")[-1]\n",
    "model_name = model_info.name\n",
    "print(\"Name:\", model_name)\n",
    "print(\"Description:\", model_info.description)\n",
    "print(\"Tags:\", model_info.tags)\n",
    "latest_version = model_manager.get_latest_version(model_info.name)\n",
    "print(\"Latest Version:\", latest_version.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering a New Model Version from Checkpoint\n",
    "\n",
    "Suppose to train a new PPO Agent in the CartPole-v1 environment and to obtain better results than before. You can register a new version of the model. To do this, we show another method to register models, not directly after training, but from a checkpoint.\n",
    "\n",
    "First of all, we need to run another experiment with different hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve the configs, we can simulate the cli command\n",
    "# `python sheeprl.py exp=ppo algo.total_steps=16384 checkpoint.every=16384 logger@metric.logger=mlflow exp_name=mlflow_example metric.logger.tracking_uri=\"http://localhost:5000\"`\n",
    "import os\n",
    "\n",
    "with hydra.initialize(version_base=\"1.3\", config_path=\"../sheeprl/configs\"):\n",
    "    cfg_ = hydra.compose(\n",
    "        config_name=\"config.yaml\",\n",
    "        overrides=[\n",
    "            \"exp=ppo\",\n",
    "            \"algo.total_steps=16384\",\n",
    "            \"checkpoint.every=16384\",\n",
    "            \"logger@metric.logger=mlflow\",\n",
    "            \"exp_name=mlflow_example\",\n",
    "            \"metric.logger.tracking_uri=http://localhost:5000\",\n",
    "        ],\n",
    "    )\n",
    "    cfg = dotdict(OmegaConf.to_container(cfg_, resolve=True, throw_on_missing=True))\n",
    "run_algorithm(cfg)\n",
    "os.mkdir(f\"./logs/runs/{cfg.root_dir}/{cfg.run_name}/.hydra/\")\n",
    "OmegaConf.save(cfg_, f\"./logs/runs/{cfg.root_dir}/{cfg.run_name}/.hydra/config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `./sheeprl_model_manager.py` script to take a checkpoint and register the models of the checkpoint.\n",
    "We want to retrieve the id of the last run, to associate the model to the correct run. We can take it from the UI (from the browser) or by retrieving it with the `mlflow.search_runs(experiment_ids=[exp.experiment_id])` instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sheeprl.cli import registration\n",
    "\n",
    "# To retrieve the configs, we can simulate the cli command\n",
    "# `python sheeprl_model_manager.py checkpoint_path=</path/to/checkpoint.ckpt> \\\n",
    "# model_manager=ppo model_manager.models.agent.description='New PPO Agent version trained in CartPole-v1 environment' \\\n",
    "# run.id=<run_id>`\n",
    "runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n",
    "run_id = runs[\"run_id\"][0]\n",
    "with hydra.initialize(version_base=\"1.3\", config_path=\"../sheeprl/configs\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"model_manager_config.yaml\",\n",
    "        overrides=[\n",
    "            # Substitute the checkpoint path with your /path/to/checkpoint.ckpt\n",
    "            \"checkpoint_path=./path/to/checkpoint.ckpt\",\n",
    "            \"model_manager=ppo\",\n",
    "            \"model_manager.models.agent.description='New PPO Agent version trained in CartPole-v1 environment'\",\n",
    "            f\"run.id={run_id}\",\n",
    "        ],\n",
    "    )\n",
    "registration(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, we can retrieve the new information of the registered model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = mlflow.search_registered_models(filter_string=f\"name='{model_name}'\")[-1]\n",
    "print(\"Name:\", model_info.name)\n",
    "print(\"Description:\", model_info.description)\n",
    "print(\"Tags:\", model_info.tags)\n",
    "latest_version = model_manager.get_latest_version(model_info.name)\n",
    "print(\"Latest Version:\", latest_version.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staging the Model\n",
    "After registering the model, we can transition the model to a new stage. We can transition the model to the `\"staging\"` stage with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.transition_model(\n",
    "    model_name=\"mlflow_example_agent\",\n",
    "    version=latest_version.version,\n",
    "    stage=\"staging\",\n",
    "    description=\"Staging Model for demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Model\n",
    "You can download the registered models and load them with the `torch.load()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "download_path = \"./models/ppo-agent-cartpole\"\n",
    "model_manager.download_model(model_name, latest_version.version, download_path)\n",
    "agent = torch.load(\"models/ppo-agent-cartpole/agent/data/model.pth\")\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Best Models\n",
    "Another possibility is to register the best models of a specific experiment. Let us suppose we want to register the best model of the two experiments we ran before: the only thing we have to do is to call the `model_manager.register_best_models()` function by specifying the `experiment_name`, the `metric`, and the `models_info` (a python dictionary containing the name, the path, the description and the tags of the models we want to register), as shown below.\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> If your experiment contains different agents, and each agent has different model paths, then you have to specify in the `models_info` all the models you want to register (i.e., the union of the models of all the agents). The MLFlow model manager will automatically select the correct models for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    \"agent\": {\n",
    "        \"name\": \"ppo_agent_cartpole_best_reward\",\n",
    "        \"path\": \"agent\",\n",
    "        \"tags\": {},\n",
    "        \"description\": \"The best PPO Agent in CartPole environment.\",\n",
    "    }\n",
    "}\n",
    "model_manager.register_best_models(\"mlflow_example\", models_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Model\n",
    "Finally, you can delete registered models you no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.delete_model(\n",
    "    model_name, int(latest_version.version) - 1, f\"Delete model version {int(latest_version.version)-1}\"\n",
    ")\n",
    "mlflow.search_registered_models(filter_string=\"name='mlflow_example_agent'\")[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheeprl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
