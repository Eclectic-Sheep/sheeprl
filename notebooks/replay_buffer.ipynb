{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from tensordict import TensorDict\n",
    "\n",
    "from fabricrl.data.buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_size = 16\n",
    "seq_len = 2\n",
    "n_envs = 3\n",
    "rb = ReplayBuffer(buf_size, n_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDict(\n",
    "    {\n",
    "        \"observations\": torch.rand(seq_len, n_envs, 4),\n",
    "        \"actions\": torch.randint(0, 4, (seq_len, n_envs, 1)),\n",
    "        \"rewards\": torch.rand(seq_len, n_envs, 1),\n",
    "        \"dones\": torch.randint(0, 2, (seq_len, n_envs, 1)),\n",
    "    },\n",
    "    batch_size=[seq_len, n_envs],\n",
    ")\n",
    "data.shape, rb._buf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not rb._full:\n",
    "    rb.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.buffer.view(math.prod(rb.buffer.shape), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb[\"returns\"] = torch.rand(16, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.buffer.view(math.prod(rb.shape), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_in = torch.arange(16)\n",
    "mask = torch.tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0]).bool()\n",
    "arr_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_arr_in = torch.nn.utils.rnn.pad_sequence(\n",
    "    torch.tensor_split(arr_in.float(), mask.nonzero().view(-1) + 1), batch_first=True, padding_value=0\n",
    ")\n",
    "flip_pad_arr_in = pad_arr_in.fliplr()\n",
    "cs = flip_pad_arr_in.cumsum(dim=1).fliplr()\n",
    "cs[cs.nonzero(as_tuple=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get classical cumsum\n",
    "cs = arr_in.cumsum(dim=0)\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(mask, cs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = torch.cummax(torch.where(mask, cs, 0), 0)[0].roll(1, 0)\n",
    "acc[0] = 0\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs - acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify 0s\n",
    "arr_in = np.arange(16)\n",
    "mask = np.array([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])\n",
    "\n",
    "# get classical cumsum\n",
    "cs = (np.ones(arr_in.shape[0]) * (1 - mask)).cumsum()\n",
    "print(cs)\n",
    "\n",
    "w = mask * cs\n",
    "print(w)\n",
    "\n",
    "m = np.maximum.accumulate(w)\n",
    "print(m)\n",
    "\n",
    "# ffill the cumsum value on 1s\n",
    "# subtract from cumsum\n",
    "out = cs - m\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "\n",
    "gamma = 0.99\n",
    "gae_lambda = 0.95\n",
    "\n",
    "\n",
    "def conditional_arange(n: int, mask: Tensor) -> Tensor:\n",
    "    rolled_mask = torch.roll(mask, 1, 0)\n",
    "    rolled_mask[0] = 0\n",
    "    cs = (torch.ones(n) * (1 - rolled_mask)).cumsum(dim=0)\n",
    "    acc = torch.cummax(rolled_mask * cs, 0)[0]\n",
    "    return cs - torch.where(acc > 0, acc - 1, 0) - 1\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_returns_and_advantages(\n",
    "    rewards: Tensor,\n",
    "    values: Tensor,\n",
    "    dones: Tensor,\n",
    "    next_done: Tensor,\n",
    "    next_value: Tensor,\n",
    "    num_steps: int,\n",
    "    gamma: float,\n",
    "    gae_lambda: float,\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    advantages = torch.zeros_like(rewards)\n",
    "    lastgaelam = 0\n",
    "    for t in reversed(range(num_steps)):\n",
    "        if t == num_steps - 1:\n",
    "            nextnonterminal = torch.logical_not(next_done)\n",
    "            nextvalues = next_value\n",
    "        else:\n",
    "            nextnonterminal = torch.logical_not(dones[t + 1])\n",
    "            nextvalues = values[t + 1]\n",
    "        delta = rewards[t] + gamma * nextvalues * nextnonterminal - values[t]\n",
    "        advantages[t] = lastgaelam = delta + gamma * gae_lambda * nextnonterminal * lastgaelam\n",
    "    returns = advantages + values\n",
    "    return returns, advantages\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def fast_estimate_returns_and_advantages(\n",
    "    rewards: Tensor,\n",
    "    values: Tensor,\n",
    "    dones: Tensor,\n",
    "    next_done: Tensor,\n",
    "    next_value: Tensor,\n",
    "    gamma: float,\n",
    "    gae_lambda: float,\n",
    "):\n",
    "    if len(rewards.shape) == 3:\n",
    "        t_steps = torch.cat(\n",
    "            [\n",
    "                conditional_arange(values.shape[0], dones[:, dim, :].view(-1)).view(-1, 1)\n",
    "                for dim in range(rewards.shape[1])\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "    elif len(rewards.shape) == 2:\n",
    "        t_steps = conditional_arange(values.shape[0], dones.view(-1)).view(-1, 1)\n",
    "    else:\n",
    "        raise ValueError(\"Shape must be 2 or 3 dimensional\")\n",
    "    gt = torch.pow(gamma * gae_lambda, t_steps.view_as(dones))\n",
    "    next_values = torch.roll(values, -1, dims=0)\n",
    "    next_values[-1] = next_value\n",
    "    next_dones = torch.roll(dones, -1, dims=0)\n",
    "    next_dones[-1] = next_done\n",
    "    deltas = rewards + gamma * next_values * (1 - next_dones) - values\n",
    "    cs = torch.flipud(deltas * gt).cumsum(dim=0)\n",
    "    acc = torch.cummax(torch.flipud(dones) * cs, 0)[0]\n",
    "    acc[0] = 0\n",
    "    dones[-1] = 0\n",
    "    # mask = dones.nonzero(as_tuple=True)\n",
    "    # adv = torch.flipud(cs - acc) / gt\n",
    "    # adv[mask] = deltas[mask] + gamma * gae_lambda * adv[mask[0] + 1, mask[1]]\n",
    "    adv = torch.flipud(cs - acc) / gt\n",
    "    return adv + dones * (deltas + gamma * gae_lambda * adv.roll(-1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 256\n",
    "batch_size = 2\n",
    "rewards = torch.rand(num_steps, 1).tanh()\n",
    "values = torch.rand(num_steps, 1)\n",
    "dones = torch.zeros(num_steps, 1)\n",
    "dones[0, 0] = 1.0\n",
    "dones[-1, 0] = 1.0\n",
    "next_done = torch.zeros(1, 1) + 1\n",
    "next_value = torch.rand(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = estimate_returns_and_advantages(rewards, values, dones, next_done, next_value, num_steps, gamma, gae_lambda)\n",
    "r[1].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = fast_estimate_returns_and_advantages(rewards, values, dones, next_done, next_value, gamma, gae_lambda)\n",
    "fr.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(r[1], fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import func as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = fc.vmap(fast_estimate_returns_and_advantages, in_dims=(1, 1, 1, 1, 1, None, None), out_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = v(rewards, values, dones, next_done, next_value, gamma, gae_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(r[1][:, 1, :], vr[:, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(8)\n",
    "m = torch.tensor([1, 0, 0, 1, 0, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = a.cumsum(0)\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cummax(m * cs, 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs - torch.cummax(m * cs, 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensordict.nn import dispatch\n",
    "from tensordict import TensorDict\n",
    "\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    in_keys = [\"a\"]\n",
    "    out_keys = [\"b\"]\n",
    "\n",
    "    @dispatch\n",
    "    def forward(self, tensordict, c, d=1, e=2):\n",
    "        print(\"c:\", c, \"d:\", d, \"e:\", e)\n",
    "        tensordict[\"b\"] = tensordict[\"a\"] + 1\n",
    "        return tensordict\n",
    "\n",
    "    @dispatch(source=[\"c\"], dest=[\"d\"])\n",
    "    def test(self, tensordict, a=42, b=None):\n",
    "        print(a, b)\n",
    "        tensordict[\"d\"] = tensordict[\"c\"] + 1\n",
    "        return tensordict, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TensorDict({\"a\": torch.zeros(16, 1)}, batch_size=[16])\n",
    "o = m(a, c=\"abracadabra\", d=None, e=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TensorDict({\"c\": torch.zeros(16, 1)}, batch_size=[16])\n",
    "o = m.test(a, a=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fabricrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
