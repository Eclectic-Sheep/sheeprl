# @package _global_

defaults:
  - dreamer_v3
  - override /env: diambra
  - _self_

# Experiment
seed: 0

# Environment
env:
  id: doapp
  num_envs: 4
  grayscale: True
  frame_stack: 1
  screen_size: 128
  reward_as_observation: True
  wrapper:
    diambra_settings:
      role: null
      characters: null
      difficulty: 4
    diambra_wrappers:
      no_attack_buttons_combinations: False

# Checkpoint
checkpoint:
  every: 100000

# Buffer
buffer:
  checkpoint: True

# Algorithm
algo:
  total_steps: 10000000
  per_rank_batch_size: 8
  learning_starts: 65536
  train_every: 8
  dense_units: 768
  mlp_layers: 4
  world_model:
    encoder:
      cnn_channels_multiplier: 64
    recurrent_model:
      recurrent_state_size: 2048
    transition_model:
      hidden_size: 768
    representation_model:
      hidden_size: 768
  cnn_keys:
    encoder:
      - frame
  mlp_keys:
    encoder:
      - own_character
      - own_health
      - own_side
      - own_wins
      - opp_character
      - opp_health
      - opp_side
      - opp_wins
      - stage
      - timer
      - action
      - reward
    decoder:
      - own_character
      - own_health
      - own_side
      - own_wins
      - opp_character
      - opp_health
      - opp_side
      - opp_wins
      - stage
      - timer
      - action

# Metric
metric:
  log_every: 10000
