# @package _global_

defaults:
  - override /algo: ppo
  - override /env: super_mario_bros
  - override /model_manager: ppo
  - _self_

# Environment
env:
  num_envs: 8

# Algorithm
algo:
  # total_steps: 524288
  # total_steps: 262144
  total_steps: 1048576
  # total_steps: 2097152
  max_grad_norm: 0.5
  per_rank_batch_size: 256
  rollout_steps: 2048
  dense_units: 64
  encoder:
    cnn_features_dim: 512
  cnn_keys:
    encoder: [rgb]

# Buffer
buffer:
  share_data: False
  size: ${algo.rollout_steps}

# Checkpoint
checkpoint:
  every: 50000

metric:
  aggregator:
    metrics:
      Loss/value_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/policy_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/entropy_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}

fabric:
  accelerator: cuda
